{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport cv2\nimport os\nimport glob\nfrom skimage import io \n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow.python.keras import Sequential \nfrom tensorflow.keras import optimizers,layers \nfrom tensorflow.keras.layers import *          \nfrom tensorflow.keras.models import Model       \nfrom tensorflow.keras.initializers import glorot_uniform \nfrom tensorflow.keras.utils import plot_model   #\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint,LearningRateScheduler # The Modules itself signifies the meaning\nimport tensorflow.keras.backend as K\n\nfrom sklearn.model_selection import train_test_split\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:58:38.628497Z","iopub.execute_input":"2022-07-04T11:58:38.628929Z","iopub.status.idle":"2022-07-04T11:58:44.865488Z","shell.execute_reply.started":"2022-07-04T11:58:38.628836Z","shell.execute_reply":"2022-07-04T11:58:44.864114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/lgg-mri-segmentation/kaggle_3m/data.csv')\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:58:44.871174Z","iopub.execute_input":"2022-07-04T11:58:44.872042Z","iopub.status.idle":"2022-07-04T11:58:44.942877Z","shell.execute_reply.started":"2022-07-04T11:58:44.872003Z","shell.execute_reply":"2022-07-04T11:58:44.941719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:58:44.944599Z","iopub.execute_input":"2022-07-04T11:58:44.945177Z","iopub.status.idle":"2022-07-04T11:58:44.975863Z","shell.execute_reply.started":"2022-07-04T11:58:44.94514Z","shell.execute_reply":"2022-07-04T11:58:44.97479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# basic stats\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:58:44.98116Z","iopub.execute_input":"2022-07-04T11:58:44.981455Z","iopub.status.idle":"2022-07-04T11:58:45.061407Z","shell.execute_reply.started":"2022-07-04T11:58:44.981427Z","shell.execute_reply":"2022-07-04T11:58:45.060429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null_rate_df = pd.DataFrame(columns=['Column','Count','null_rate'])\n\nnull_rate_df['Column'] = [i for i in df.columns]\nnull_rate_df['Count'] = [j for j in df.isnull().sum()]\n\n# null rate\nnull_rates = df.isnull().sum()/df.shape[0]*100\nnull_rate_df['null_rate'] = [k for k in null_rates]","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:58:45.065566Z","iopub.execute_input":"2022-07-04T11:58:45.065954Z","iopub.status.idle":"2022-07-04T11:58:45.082687Z","shell.execute_reply.started":"2022-07-04T11:58:45.065922Z","shell.execute_reply":"2022-07-04T11:58:45.081505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null_rate_df","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:58:45.086823Z","iopub.execute_input":"2022-07-04T11:58:45.089561Z","iopub.status.idle":"2022-07-04T11:58:45.108119Z","shell.execute_reply.started":"2022-07-04T11:58:45.089487Z","shell.execute_reply":"2022-07-04T11:58:45.107283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_map = []\n# iterate in each of the folder inside the lgg-mri-segmantation/kaggle_3m\nfor sub_dir_path in glob.glob('/kaggle/input/lgg-mri-segmentation/kaggle_3m/'+'*'): \n    try:\n        dir_name = sub_dir_path.split('/')[-1]\n        for filename in os.listdir(sub_dir_path):              # iterat in each of the instances\n            image_path = sub_dir_path+'/'+filename             # total file path\n            data_map.extend([dir_name,image_path])             # Appending the name, image path\n    except Exception as e:\n        print(e)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:58:45.112082Z","iopub.execute_input":"2022-07-04T11:58:45.114155Z","iopub.status.idle":"2022-07-04T11:58:46.822546Z","shell.execute_reply.started":"2022-07-04T11:58:45.114121Z","shell.execute_reply":"2022-07-04T11:58:46.821202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.DataFrame({\"patient_id\":data_map[::2],'path':data_map[1::2]}) # Creating a final dataframe of name, path\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:58:46.824498Z","iopub.execute_input":"2022-07-04T11:58:46.824882Z","iopub.status.idle":"2022-07-04T11:58:46.838916Z","shell.execute_reply.started":"2022-07-04T11:58:46.824842Z","shell.execute_reply":"2022-07-04T11:58:46.837844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a dataframe of the path of the images\ndf_imgs = data[~data['path'].str.contains('mask')]     \n# create a dataframe of path of the mask of the image\ndf_masks = data[data['path'].str.contains('mask')]       \nBASE_LEN = 89\nEND_IMG_LEN = 4\nEND_MASK_LEN=9\n\n# data Sorting\nimgs = sorted(df_imgs['path'].values,key = lambda x: int(x[BASE_LEN:-END_IMG_LEN])) # sorting by last numbers\nmasks = sorted(df_masks['path'].values,key = lambda x:int(x[BASE_LEN:-END_MASK_LEN])) #similar as above (due to this sorting, we would get a pair of image path, and mask path)\n\nidx = random.randint(0,len(imgs)-1)\nprint(\"Path to the image:\",imgs[idx],'\\nPath to the Mask:',masks[idx])","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:58:46.84083Z","iopub.execute_input":"2022-07-04T11:58:46.84118Z","iopub.status.idle":"2022-07-04T11:58:46.866315Z","shell.execute_reply.started":"2022-07-04T11:58:46.841145Z","shell.execute_reply":"2022-07-04T11:58:46.865342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"brain_df = pd.DataFrame({'patient_id':df_imgs.patient_id.values,\n                    'image_path':imgs,'mask_path':masks})         # create a dataframe containing the id, the image path and the mask path\n\ndef pos_neg_diagnosis(mask_path):\n    value = np.max(cv2.imread(mask_path))                         # this is for determining whether tumor exists or not\n    if value>0:\n        return 1\n    else:\n        return 0\nbrain_df['mask'] = brain_df['mask_path'].apply(lambda x:pos_neg_diagnosis(x))\nbrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:58:46.870368Z","iopub.execute_input":"2022-07-04T11:58:46.870775Z","iopub.status.idle":"2022-07-04T11:59:06.638342Z","shell.execute_reply.started":"2022-07-04T11:58:46.870747Z","shell.execute_reply":"2022-07-04T11:59:06.636956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask = brain_df['mask'].value_counts()\nlabels = mask.keys()\nbar,ax = plt.subplots(figsize=(5,5))\nplt.pie(x = mask, labels = labels, autopct=\"%.2f%%\",pctdistance=0.7)\nplt.title('Mask', fontsize=20)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:59:06.639837Z","iopub.execute_input":"2022-07-04T11:59:06.640376Z","iopub.status.idle":"2022-07-04T11:59:06.823817Z","shell.execute_reply.started":"2022-07-04T11:59:06.64034Z","shell.execute_reply":"2022-07-04T11:59:06.822509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor i in range(len(brain_df)):\n    if cv2.imread(brain_df['mask_path'][i]).max()>0:\n        break\n\nplt.figure(figsize=(12,8))\nplt.subplot(121)\nplt.imshow(cv2.imread(brain_df['mask_path'][i]));\nplt.title('Tumor Location')\nplt.axis('off')\nplt.subplot(122)\nplt.imshow(cv2.imread(brain_df['image_path'][i]));\nplt.title(\"Brain MRI Image\")\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:59:06.828234Z","iopub.execute_input":"2022-07-04T11:59:06.830802Z","iopub.status.idle":"2022-07-04T11:59:07.769584Z","shell.execute_reply.started":"2022-07-04T11:59:06.830764Z","shell.execute_reply":"2022-07-04T11:59:07.768671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,axs = plt.subplots(10,2,figsize=(16,26))\ncount = 0\nfor x in range(10):\n    i = random.randint(0,len(brain_df))\n    axs[count][0].title.set_text(\"Brain MRI\")\n    axs[count][0].imshow(cv2.imread(brain_df['image_path'][i]))\n    axs[count][1].title.set_text(\"Mask - \"+str(brain_df['mask'][i]))\n    axs[count][1].imshow(cv2.imread(brain_df['mask_path'][i]))\n    axs[count][0].axis('off')\n    axs[count][1].axis('off')\n    count+=1\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:59:07.770612Z","iopub.execute_input":"2022-07-04T11:59:07.770927Z","iopub.status.idle":"2022-07-04T11:59:09.243087Z","shell.execute_reply.started":"2022-07-04T11:59:07.77089Z","shell.execute_reply":"2022-07-04T11:59:09.240511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 0\ni = 0\nfig,axs= plt.subplots(10,3,figsize=(20,50))\nfor mask in brain_df['mask']:\n    if(mask==1):\n        img = io.imread(brain_df['image_path'][i])\n        axs[count][0].title.set_text(\"Brain MRI\")\n        axs[count][0].imshow(img)\n        \n        mask = io.imread(brain_df['mask_path'][i])\n        axs[count][1].title.set_text('Mask')\n        axs[count][1].imshow(mask,cmap ='gray')\n        img[mask==255]=(0,255,150)\n        axs[count][2].title.set_text('MRI with Mask')\n        axs[count][2].imshow(img)\n        axs[count][0].axis('off')\n        axs[count][1].axis('off')\n        axs[count][2].axis('off')\n        count+=1\n    i+=1\n    if(count==10):\n        break\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:59:09.244612Z","iopub.execute_input":"2022-07-04T11:59:09.245555Z","iopub.status.idle":"2022-07-04T11:59:11.860062Z","shell.execute_reply.started":"2022-07-04T11:59:09.245503Z","shell.execute_reply":"2022-07-04T11:59:11.859121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"brain_df_train = brain_df.drop(columns=['patient_id'])\nbrain_df_train['mask'] = brain_df_train['mask'].apply(lambda x: str(x))\nbrain_df_train.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:59:11.861287Z","iopub.execute_input":"2022-07-04T11:59:11.862089Z","iopub.status.idle":"2022-07-04T11:59:11.882116Z","shell.execute_reply.started":"2022-07-04T11:59:11.862059Z","shell.execute_reply":"2022-07-04T11:59:11.881246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"brain_df_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:59:11.883394Z","iopub.execute_input":"2022-07-04T11:59:11.884102Z","iopub.status.idle":"2022-07-04T11:59:11.900506Z","shell.execute_reply.started":"2022-07-04T11:59:11.884075Z","shell.execute_reply":"2022-07-04T11:59:11.899582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train,test = train_test_split(brain_df_train,test_size=0.15) ","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:59:11.902115Z","iopub.execute_input":"2022-07-04T11:59:11.90249Z","iopub.status.idle":"2022-07-04T11:59:11.912679Z","shell.execute_reply.started":"2022-07-04T11:59:11.902453Z","shell.execute_reply":"2022-07-04T11:59:11.909601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(rescale=1./255,validation_split=0.1)\n# Creating dataset\ntrain_generator = datagen.flow_from_dataframe(train,directory = './',\n                x_col = 'image_path',y_col='mask',subset='training',class_mode='categorical',\n                                             batch_size=16,shuffle=True,target_size=(256,256))\nvalid_generator = datagen.flow_from_dataframe(train,directory='./',\n                                x_col = 'image_path',y_col = 'mask',\n                                             subset='validation',class_mode='categorical',batch_size=16,shuffle=True,target_size=(256,256))\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_dataframe(test,directory='./',x_col='image_path',y_col = 'mask',class_mode='categorical',batch_size=16,shuffle=False,target_size=(256,256))","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:59:11.914965Z","iopub.execute_input":"2022-07-04T11:59:11.915475Z","iopub.status.idle":"2022-07-04T11:59:13.393242Z","shell.execute_reply.started":"2022-07-04T11:59:11.915438Z","shell.execute_reply":"2022-07-04T11:59:13.392206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.resnet50 import ResNet50\nclf_model = ResNet50(weights='imagenet',include_top=False,input_tensor = Input(shape=(256,256,3)))\nclf_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:59:13.394555Z","iopub.execute_input":"2022-07-04T11:59:13.394983Z","iopub.status.idle":"2022-07-04T11:59:18.208236Z","shell.execute_reply.started":"2022-07-04T11:59:13.394945Z","shell.execute_reply":"2022-07-04T11:59:18.207264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"head = clf_model.output\nhead = AveragePooling2D(pool_size=(4,4))(head)\nhead = Flatten(name='Flatten')(head)\nhead = Dense(256,activation='relu')(head)\nhead = Dropout(0.3)(head)\nhead = Dense(256,activation='relu')(head)\nhead = Dropout(0.3)(head)\nhead = Dense(2,activation='softmax')(head)\n\nmodel = Model(clf_model.input,head)\nmodel.compile(loss='categorical_crossentropy',\n             optimizer='adam',metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:59:18.213704Z","iopub.execute_input":"2022-07-04T11:59:18.214014Z","iopub.status.idle":"2022-07-04T11:59:18.296333Z","shell.execute_reply.started":"2022-07-04T11:59:18.213985Z","shell.execute_reply":"2022-07-04T11:59:18.295394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping= EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=5) \ncheck_pointer = ModelCheckpoint(filepath = 'clf-resnet-checkpoint.hdf5',verbose=1,save_best_only=True) \nreduce_lr = ReduceLROnPlateau(monitor='val_loss',mode='min',verbose=1,patience=5,min_delta = 0.0001,factor=0.2) \ncallbacks = [check_pointer,early_stopping,reduce_lr]","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:59:18.297929Z","iopub.execute_input":"2022-07-04T11:59:18.298579Z","iopub.status.idle":"2022-07-04T11:59:18.305709Z","shell.execute_reply.started":"2022-07-04T11:59:18.298527Z","shell.execute_reply":"2022-07-04T11:59:18.304824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h = model.fit(train_generator,steps_per_epoch = train_generator.n//train_generator.batch_size,\n                        epochs=30,validation_data=valid_generator,validation_steps = valid_generator.n//valid_generator.batch_size,\n                             callbacks = [check_pointer,early_stopping])","metadata":{"execution":{"iopub.status.busy":"2022-07-04T11:59:18.307213Z","iopub.execute_input":"2022-07-04T11:59:18.307603Z","iopub.status.idle":"2022-07-04T12:14:42.408706Z","shell.execute_reply.started":"2022-07-04T11:59:18.307564Z","shell.execute_reply":"2022-07-04T12:14:42.407614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saving the Model architecture in json file\nmodel_json = model.to_json()\nwith open('clf-resnet.json','w') as json_file:\n    json_file.write(model_json)\nmodel.save('clf-brain.h5')\n","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:14:42.410944Z","iopub.execute_input":"2022-07-04T12:14:42.411628Z","iopub.status.idle":"2022-07-04T12:14:43.584586Z","shell.execute_reply.started":"2022-07-04T12:14:42.411582Z","shell.execute_reply":"2022-07-04T12:14:43.583408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,5))\nplt.subplot(121)\nplt.plot(h.history['loss'])\nplt.plot(h.history['val_loss'])\nplt.title(\"Classification Model LOSS\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epochs\")\nplt.legend(['train','val'])\n\nplt.subplot(122)\nplt.plot(h.history['accuracy'])\nplt.plot(h.history['val_accuracy'])\nplt.title(\"Classification Model Accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.legend(['train','val'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:14:43.586396Z","iopub.execute_input":"2022-07-04T12:14:43.58676Z","iopub.status.idle":"2022-07-04T12:14:43.99163Z","shell.execute_reply.started":"2022-07-04T12:14:43.586723Z","shell.execute_reply":"2022-07-04T12:14:43.990547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_,acc = model.evaluate(test_generator)\nprint(\"Test Accuracy :  {} %\".format(acc*100))","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:14:43.996023Z","iopub.execute_input":"2022-07-04T12:14:43.996601Z","iopub.status.idle":"2022-07-04T12:14:48.482488Z","shell.execute_reply.started":"2022-07-04T12:14:43.996559Z","shell.execute_reply":"2022-07-04T12:14:48.481146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = model.predict(test_generator)\npred = np.argmax(prediction,axis=1)\noriginal = np.asarray(test['mask']).astype('int')\n\n\naccuracy = accuracy_score(original,pred)\nprint(accuracy)\n\ncm = confusion_matrix(original,pred)\nreport = classification_report(original,pred,labels=[0,1])\nprint(report)\nplt.figure(figsize=(5,5))\nsns.heatmap(cm,annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:14:48.484149Z","iopub.execute_input":"2022-07-04T12:14:48.484627Z","iopub.status.idle":"2022-07-04T12:14:51.017436Z","shell.execute_reply.started":"2022-07-04T12:14:48.484588Z","shell.execute_reply":"2022-07-04T12:14:51.016494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"brain_df_mask = brain_df[brain_df['mask']==1]\nbrain_df_mask.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:14:51.018743Z","iopub.execute_input":"2022-07-04T12:14:51.01911Z","iopub.status.idle":"2022-07-04T12:14:51.02771Z","shell.execute_reply.started":"2022-07-04T12:14:51.019074Z","shell.execute_reply":"2022-07-04T12:14:51.026753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_val = train_test_split(brain_df_mask,test_size=0.15)\nX_test,X_val = train_test_split(X_val,test_size=0.5)\n\nprint(\"Train Size is {}, validation size is {} & test size is {}\".format(len(X_train),len(X_val),len(X_test)))\n      \ntrain_ids = list(X_train.image_path)\ntrain_mask = list(X_train.mask_path)\n      \nval_ids = list(X_val.image_path)\nval_mask = list(X_val.mask_path)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:14:51.029366Z","iopub.execute_input":"2022-07-04T12:14:51.030084Z","iopub.status.idle":"2022-07-04T12:14:51.04056Z","shell.execute_reply.started":"2022-07-04T12:14:51.030046Z","shell.execute_reply":"2022-07-04T12:14:51.03954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n  def __init__(self, ids , mask, image_dir = './', batch_size = 16, img_h = 256, img_w = 256, shuffle = True):\n\n    self.ids = ids\n    self.mask = mask\n    self.image_dir = image_dir\n    self.batch_size = batch_size\n    self.img_h = img_h\n    self.img_w = img_w\n    self.shuffle = shuffle\n    self.on_epoch_end()\n\n  def __len__(self):\n    'Get the number of batches per epoch'\n\n    return int(np.floor(len(self.ids)) / self.batch_size)\n\n  def __getitem__(self, index):\n    'Generate a batch of data'\n\n    #generate index of batch_size length\n    indexes = self.indexes[index* self.batch_size : (index+1) * self.batch_size]\n\n    #get the ImageId corresponding to the indexes created above based on batch size\n    list_ids = [self.ids[i] for i in indexes]\n\n    #get the MaskId corresponding to the indexes created above based on batch size\n    list_mask = [self.mask[i] for i in indexes]\n\n\n    #generate data for the X(features) and y(label)\n    X, y = self.__data_generation(list_ids, list_mask)\n\n    #returning the data\n    return X, y\n  def on_epoch_end(self):\n\n    #get the ImageId corresponding to the indexes created above based on batch size\n    self.indexes = np.arange(len(self.ids))\n\n    #if shuffle is true, shuffle the indices\n    if self.shuffle:\n      np.random.shuffle(self.indexes)\n\n  def __data_generation(self, list_ids, list_mask):\n    'generate the data corresponding the indexes in a given batch of images'\n\n    # create empty arrays of shape (batch_size,height,width,depth) \n    #Depth is 3 for input and depth is taken as 1 for output becasue mask consist only of 1 channel.\n    X = np.empty((self.batch_size, self.img_h, self.img_w, 3))\n    y = np.empty((self.batch_size, self.img_h, self.img_w, 1))\n\n    #iterate through the dataframe rows, whose size is equal to the batch_size\n    for i in range(len(list_ids)):\n      #path of the image\n      img_path = str(list_ids[i])\n      \n      #mask path\n      mask_path = str(list_mask[i])\n      \n      #reading the original image and the corresponding mask image\n      img = io.imread(img_path)\n      mask = io.imread(mask_path)\n\n      #resizing and coverting them to array of type float64\n      img = cv2.resize(img,(self.img_h,self.img_w))\n      img = np.array(img, dtype = np.float64)\n      \n      mask = cv2.resize(mask,(self.img_h,self.img_w))\n      mask = np.array(mask, dtype = np.float64)\n\n      #standardising \n      img -= img.mean()\n      img /= img.std()\n      \n      mask -= mask.mean()\n      mask /= mask.std()\n      \n      #Adding image to the empty array\n      X[i,] = img\n      \n      #expanding the dimnesion of the image from (256,256) to (256,256,1)\n      y[i,] = np.expand_dims(mask, axis = 2)\n    \n    #normalizing y\n    y = (y > 0).astype(int)\n\n    return X, y\n\ntrain_data = DataGenerator(train_ids, train_mask)\nval_data = DataGenerator(val_ids, val_mask)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:14:51.042428Z","iopub.execute_input":"2022-07-04T12:14:51.043145Z","iopub.status.idle":"2022-07-04T12:14:51.06096Z","shell.execute_reply.started":"2022-07-04T12:14:51.043109Z","shell.execute_reply":"2022-07-04T12:14:51.060085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resblock(X,f):\n    X_copy = X\n    X  =Conv2D(f,kernel_size=(1,1),kernel_initializer='he_normal')(X)\n    X = BatchNormalization()(X)\n    X = Activation('relu')(X)\n    \n    X = Conv2D(f,kernel_size=(3,3),padding='same',kernel_initializer='he_normal')(X)\n    X = BatchNormalization()(X)\n    \n    X_copy = Conv2D(f,kernel_size=(1,1),kernel_initializer='he_normal')(X_copy)\n    X_copy = BatchNormalization()(X_copy)\n    \n    X = Add()([X,X_copy])\n    X =Activation('relu')(X)\n    \n    return X\n\ndef upsample_concat(x,skip):\n    X = UpSampling2D((2,2))(x)\n    merge = Concatenate()([X,skip])\n    return merge","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:14:51.062516Z","iopub.execute_input":"2022-07-04T12:14:51.062921Z","iopub.status.idle":"2022-07-04T12:14:51.074366Z","shell.execute_reply.started":"2022-07-04T12:14:51.062887Z","shell.execute_reply":"2022-07-04T12:14:51.073418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (256,256,3)\nX_input = Input(input_shape)\n\n# Stage 1\nconv_1 = Conv2D(16,3,activation='relu',padding='same',kernel_initializer='he_normal')(X_input)\nconv_1 =BatchNormalization()(conv_1)\nconv_1 = Conv2D(16,3,activation='relu',padding='same',kernel_initializer='he_normal')(conv_1)\nconv_1 = BatchNormalization()(conv_1)\npool_1 = MaxPool2D((2,2))(conv_1)\n\n# Stage 2\nconv_2 = resblock(pool_1,32)\npool_2 = MaxPool2D((2,2))(conv_2)\n\n# Stage 3\nconv_3 = resblock(pool_2,64)\npool_3 = MaxPool2D((2,2))(conv_3)\n\n# Stage 4\nconv_4 = resblock(pool_3,128)\npool_4 = MaxPool2D((2,2))(conv_4)\n\n# Stage 5 (bottle neck)\nconv_5 = resblock(pool_4,256)\n\n# Upsample Stage 1\nup_1 = upsample_concat(conv_5,conv_4)\nup_1 = resblock(up_1,128)\n\n# Upsample Stage 2\nup_2 = upsample_concat(up_1,conv_3)\nup_2 = resblock(up_2,64)\n\n# Upsample Stage 3\nup_3 = upsample_concat(up_2,conv_2)\nup_3 = resblock(up_3,32)\n\n# Upsample stage 4\nup_4 = upsample_concat(up_3,conv_1)\nup_4 = resblock(up_4,16)\n\nout = Conv2D(1,(1,1),kernel_initializer='he_normal',padding='same',activation='sigmoid')(up_4)\nseg_model = Model(X_input,out)\nseg_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:14:51.076216Z","iopub.execute_input":"2022-07-04T12:14:51.077078Z","iopub.status.idle":"2022-07-04T12:14:51.534125Z","shell.execute_reply.started":"2022-07-04T12:14:51.077024Z","shell.execute_reply":"2022-07-04T12:14:51.532413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(seg_model,to_file='seg_model.png')","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:14:51.5367Z","iopub.execute_input":"2022-07-04T12:14:51.537009Z","iopub.status.idle":"2022-07-04T12:14:53.626416Z","shell.execute_reply.started":"2022-07-04T12:14:51.536983Z","shell.execute_reply":"2022-07-04T12:14:53.625232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define a custom loss function for ResUNet model\n'''\nactual link for refrence (https://github.com/nabsabraham/focal-tversky-unet/blob/master/losses.py)\n'''\n\nfrom keras.losses import binary_crossentropy\n\nepsilon = 1e-5\nsmooth = 1\n\ndef tversky(y_true, y_pred):\n    y_true_pos = K.flatten(y_true)\n    y_pred_pos = K.flatten(y_pred)\n    true_pos = K.sum(y_true_pos * y_pred_pos)\n    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n    alpha = 0.7\n    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n\ndef focal_tversky(y_true,y_pred):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    pt_1 = tversky(y_true, y_pred)\n    gamma = 0.75\n    return K.pow((1-pt_1), gamma)\n\ndef tversky_loss(y_true, y_pred):\n    return 1 - tversky(y_true,y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:14:53.628109Z","iopub.execute_input":"2022-07-04T12:14:53.632042Z","iopub.status.idle":"2022-07-04T12:14:53.64436Z","shell.execute_reply.started":"2022-07-04T12:14:53.631997Z","shell.execute_reply":"2022-07-04T12:14:53.643215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compling model and callbacks functions\nadam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\nseg_model.compile(optimizer = adam, \n                  loss = focal_tversky, \n                  metrics = [tversky]\n                 )\n#callbacks\nearlystopping = EarlyStopping(monitor='val_loss',\n                              mode='min', \n                              verbose=1, \n                              patience=5\n                             )\n# save the best model with lower validation loss\ncheckpointer = ModelCheckpoint(filepath=\"seg-ResUNet-checkpoint.hdf5\", \n                               verbose=1, \n                               save_best_only=True\n                              )\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              mode='min',\n                              verbose=1,\n                              patience=5,\n                              min_delta=0.0001,\n                              factor=0.2\n                             )\n","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:14:53.646043Z","iopub.execute_input":"2022-07-04T12:14:53.647264Z","iopub.status.idle":"2022-07-04T12:14:53.671433Z","shell.execute_reply.started":"2022-07-04T12:14:53.647226Z","shell.execute_reply":"2022-07-04T12:14:53.670425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h = seg_model.fit(train_data,epochs = 30,validation_data = val_data,callbacks=[checkpointer,early_stopping,reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:14:53.673006Z","iopub.execute_input":"2022-07-04T12:14:53.673612Z","iopub.status.idle":"2022-07-04T12:18:49.906304Z","shell.execute_reply.started":"2022-07-04T12:14:53.673574Z","shell.execute_reply":"2022-07-04T12:18:49.905389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# saving model achitecture in json file\nseg_model_json = seg_model.to_json()\nwith open(\"seg-ResUNet.json\", \"w\") as json_file:\n    json_file.write(seg_model_json)\nseg_model.save('seg_brain.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:18:49.90822Z","iopub.execute_input":"2022-07-04T12:18:49.908597Z","iopub.status.idle":"2022-07-04T12:18:51.722423Z","shell.execute_reply.started":"2022-07-04T12:18:49.908556Z","shell.execute_reply":"2022-07-04T12:18:51.721414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h.history.keys()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:18:51.726125Z","iopub.execute_input":"2022-07-04T12:18:51.726454Z","iopub.status.idle":"2022-07-04T12:18:51.732161Z","shell.execute_reply.started":"2022-07-04T12:18:51.726424Z","shell.execute_reply":"2022-07-04T12:18:51.731287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,5))\nplt.subplot(1,2,1)\nplt.plot(h.history['loss']);\nplt.plot(h.history['val_loss']);\nplt.title(\"SEG Model focal tversky Loss\");\nplt.ylabel(\"focal tversky loss\");\nplt.xlabel(\"Epochs\");\nplt.legend(['train', 'val']);\n\nplt.subplot(1,2,2)\nplt.plot(h.history['tversky']);\nplt.plot(h.history['val_tversky']);\nplt.title(\"SEG Model tversky score\");\nplt.ylabel(\"tversky Accuracy\");\nplt.xlabel(\"Epochs\");\nplt.legend(['train', 'val']);","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:18:51.739358Z","iopub.execute_input":"2022-07-04T12:18:51.739633Z","iopub.status.idle":"2022-07-04T12:18:52.053101Z","shell.execute_reply.started":"2022-07-04T12:18:51.739608Z","shell.execute_reply":"2022-07-04T12:18:52.051617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ids = list(X_test.image_path)\ntest_mask = list(X_test.mask_path)\ntest_data = DataGenerator(test_ids, test_mask)\n_, tv = seg_model.evaluate(test_data)\nprint(\"Segmentation tversky is {:.2f}%\".format(tv*100))","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:18:52.05462Z","iopub.execute_input":"2022-07-04T12:18:52.054896Z","iopub.status.idle":"2022-07-04T12:18:52.86623Z","shell.execute_reply.started":"2022-07-04T12:18:52.054871Z","shell.execute_reply":"2022-07-04T12:18:52.865218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction(test,model,model_seg):\n    mask,image_id,has_mask = [],[],[]\n    \n    for i in test.image_path:\n        img = io.imread(i)\n        img=img*1./255.0\n        img = cv2.resize(img,(256,256))\n        img = np.array(img,dtype=np.float64)\n        img = np.reshape(img,(1,256,256,3))\n        \n        is_defect = model.predict(img)\n        \n        if np.argmax(is_defect) ==0:\n            image_id.append(i)\n            has_mask.append(0)\n            mask.append(\"No Mask :)\")\n            continue\n        \n        X = np.empty((1,256,256,3))\n        img = io.imread(i)\n        img = cv2.resize(img,(256,256))\n        img = np.array(img,dtype=np.float64)\n        img-=img.mean()\n        img/=img.std()\n        X[0,] = img\n        predict = model_seg.predict(X)\n        if predict.round().astype(int).sum()==0:\n            image_id.append(i)\n            has_mask.append(0)\n            mask.append(\"No Mask :)\")\n        else:\n            image_id.append(i)\n            has_mask.append(1)\n            mask.append(predict)\n    return pd.DataFrame({\"image_path\":image_id,'predicted_mask':mask,'has_mask':has_mask})\n","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:18:52.867901Z","iopub.execute_input":"2022-07-04T12:18:52.868287Z","iopub.status.idle":"2022-07-04T12:18:52.880167Z","shell.execute_reply.started":"2022-07-04T12:18:52.868248Z","shell.execute_reply":"2022-07-04T12:18:52.87892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pred = prediction(test,model,seg_model)\ndf_pred","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:18:52.881776Z","iopub.execute_input":"2022-07-04T12:18:52.882139Z","iopub.status.idle":"2022-07-04T12:19:38.117584Z","shell.execute_reply.started":"2022-07-04T12:18:52.882101Z","shell.execute_reply":"2022-07-04T12:19:38.116661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pred = test.merge(df_pred,on='image_path')\ndf_pred.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:19:38.118919Z","iopub.execute_input":"2022-07-04T12:19:38.119378Z","iopub.status.idle":"2022-07-04T12:19:43.251391Z","shell.execute_reply.started":"2022-07-04T12:19:38.119339Z","shell.execute_reply":"2022-07-04T12:19:43.250425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 0\nfig,axs = plt.subplots(15,5,figsize=(40,80))\nfor i in range(len(df_pred)):\n    if df_pred.has_mask[i]==1 and count<15:\n        img = io.imread(df_pred.image_path[i])\n        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        axs[count][0].imshow(img)\n        axs[count][0].title.set_text(\"Brain MRI\")\n        axs[count][0].axis('off')\n        \n        mask = io.imread(df_pred.mask_path[i])\n        axs[count][1].imshow(mask)\n        axs[count][1].title.set_text(\"Original Mask\")\n        axs[count][1].axis('off')\n        \n        pred = np.array(df_pred.predicted_mask[i]).squeeze().round()\n        axs[count][2].imshow(pred)\n        axs[count][2].title.set_text(\"AI Predicted Mask\")\n        axs[count][2].axis('off')\n        \n        img[mask==255] =(255,0,0)\n        axs[count][3].imshow(img)\n        axs[count][3].title.set_text(\"Brain MRI with original Mask (Ground Truth)\")\n        axs[count][3].axis('off')\n        \n        img_ = io.imread(df_pred.image_path[i])\n        img_ = cv2.cvtColor(img_,cv2.COLOR_BGR2RGB)\n        img_[pred==1]= (0,255,150)\n        axs[count][4].imshow(img_)\n        axs[count][4].title.set_text(\"MRI with AI Predicted Mask\")\n        axs[count][4].axis('off')\n        count+=1\n    if(count==15):\n        break\nfig.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T12:19:43.252804Z","iopub.execute_input":"2022-07-04T12:19:43.253803Z","iopub.status.idle":"2022-07-04T12:19:49.732128Z","shell.execute_reply.started":"2022-07-04T12:19:43.25376Z","shell.execute_reply":"2022-07-04T12:19:49.730857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}